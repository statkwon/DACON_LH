{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import sys"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def make_dict(text):\n",
    "    text = text.replace('null',\"'null'\")\n",
    "    return(eval(text[text.find('{'):text.find('}')+1]))\n",
    "\n",
    "def dict_extend(hh_ls, driver, typeouter):\n",
    "    req = driver.page_source\n",
    "    soup = bs(req, 'html.parser')\n",
    "    \n",
    "    for i in range(0,10):\n",
    "        try:\n",
    "            hh_ls.append(make_dict(str(soup.find_all('td', 'al')[2*i])))\n",
    "        except:\n",
    "            break\n",
    "    for i in range(0,10):\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//*[@id='schTbody']/tr[\"+str(i+1)+\"]/td[3]/a\").send_keys(Keys.ENTER)\n",
    "            time.sleep(2)\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            req = driver.page_source\n",
    "            soup = bs(req, 'html.parser')\n",
    "            num = len(soup.find('tbody',{'id':'tblByType'}).find_all('td','ac')) #매입임대는 다 ar임.\n",
    "            typeinner = []\n",
    "            overlap = [text.text for text in soup.find_all('td')][:10]\n",
    "            for j in range(0,num+1):  \n",
    "                if len(typeinner)!=0: typeouter.append(typeinner)\n",
    "                typeinner=[]\n",
    "                typeinner.extend(overlap)\n",
    "                for k in range(0,5):\n",
    "                    typeinner.append(soup.find('tbody',{'id':'tblByType'}).find_all('td',\n",
    "                    'ar')[k+5*j-5].text.replace('\\xa0',''))\n",
    "            time.sleep(2)\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "def click_wait(wait,xpath):\n",
    "    wait.until(EC.visibility_of_element_located((By.XPATH, xpath))).click()\n",
    "\n",
    "class crawl():\n",
    "    def __init__(self):\n",
    "        options = Options()\n",
    "        options.add_argument(\"window-size=1200x600\")\n",
    "        options.headless = True\n",
    "        driver = webdriver.Chrome('/Applications/chromedriver', options=options)\n",
    "        options.add_argument(\"enable-automation\")\n",
    "        options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-extensions\")\n",
    "        options.add_argument(\"--dns-prefetch-disable\")\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "        t = time.time()\n",
    "        driver.set_page_load_timeout(30)\n",
    "        driver.get('https://www.myhome.go.kr/hws/portal/sch/selectRentalHouseInfoListView.do')\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        self.driver = driver\n",
    "        self.wait = wait\n",
    "\n",
    "    def rg_crawling(self, name, reg_code):\n",
    "        hh_ls = []\n",
    "        typeouter = []\n",
    "        driver = self.driver\n",
    "        wait = self.wait\n",
    "        time.sleep(1)\n",
    "        click_wait(wait,\"//*[@id='brtcCode']/option[\"+reg_code+\"]\") # from 2 to 18  #9는 세종인데 코드수정필\n",
    "        time.sleep(10)\n",
    "        try:\n",
    "            click_wait(wait,\"//*[@id='houseTy_11']\")\n",
    "        except TimeoutException:\n",
    "            driver.execute_script(\"window.stop();\")\n",
    "        time.sleep(10)\n",
    "        click_wait(wait,\"//*[@id='frm']/div[3]/span[1]/a\")\n",
    "        time.sleep(10)\n",
    "        dict_extend(hh_ls, driver, typeouter)\n",
    "        total_num = driver.find_element_by_xpath('//*[@id=\"totCntSpan\"]/strong').text\n",
    "        total_num = int(total_num.replace(',',''))-1\n",
    "        next_iter = total_num//100 + 1\n",
    "        if int(reg_code) in [8,9,18]: #8,9,18은 2page는 말그대로 2page가 된당!\n",
    "            page_start = 2\n",
    "        else:\n",
    "            page_start = 4\n",
    "        for num in range(0,next_iter):\n",
    "            if num!=(next_iter-1):\n",
    "                page_end = 13\n",
    "            else:\n",
    "                page_end = ((total_num % 100) // 10) + 4\n",
    "            for page_num in range(page_start,page_end):\n",
    "                try:\n",
    "                    xpath = \"//*[@id='pageDiv']/ul/li[\"+str(page_num)+\"]/a\"\n",
    "                    time.sleep(3)\n",
    "                    click_wait(wait,xpath)\n",
    "                    time.sleep(3)\n",
    "                    dict_extend(hh_ls, driver, typeouter)\n",
    "                except TimeoutException:\n",
    "                    driver.execute_script(\"window.stop();\")\n",
    "                    time.sleep(3)\n",
    "                    dict_extend(hh_ls, driver, typeouter)\n",
    "                except:\n",
    "                    break\n",
    "            if num!=(next_iter-1):\n",
    "                time.sleep(3)\n",
    "                click_wait(wait,\"//*[@id='pageDiv']/ul/li[13]/a\")\n",
    "                time.sleep(3)\n",
    "                dict_extend(hh_ls, driver, typeouter)\n",
    "            else:\n",
    "                break        \n",
    "        \n",
    "        globals()[name] = pd.DataFrame.from_dict(hh_ls)\n",
    "        globals()[name+'_detail'] = pd.DataFrame(typeouter)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2=서울  \n",
    "3=부산\n",
    "4=대구\n",
    "5=인천\n",
    "6=광주\n",
    "7=대전\n",
    "8=울산 - 다른코드\n",
    "9=세종 - 다른코드\n",
    "10=경기\n",
    "11=강원\n",
    "12=충북\n",
    "13=충남\n",
    "14=전북\n",
    "15=전남\n",
    "16=겅북\n",
    "17=경남\n",
    "=충북\n",
    "13=충남\n",
    "14=전북\n",
    "15=전남\n",
    "16=겅북\n",
    "17=경남\n",
    "18=제주 - 다른코드"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "crawler = crawl()\n",
    "crawler.rg_crawling(name='seoul',reg_code='2')\n",
    "crawler.rg_crawling(name='busan',reg_code='3')\n",
    "crawler.rg_crawling(name='daegu',reg_code='4')\n",
    "crawler.rg_crawling(name='incheon',reg_code='5')\n",
    "crawler.rg_crawling(name='gwangju',reg_code='6')\n",
    "crawler.rg_crawling(name='daejeon',reg_code='7')\n",
    "crawler.rg_crawling(name='ulsan',reg_code='8')\n",
    "crawler.rg_crawling(name='sejong',reg_code='9')\n",
    "crawler.rg_crawling(name='gyeonggi',reg_code='10')\n",
    "crawler.rg_crawling(name='gangwon',reg_code='11')\n",
    "crawler.rg_crawling(name='chungbuk',reg_code='12')\n",
    "crawler.rg_crawling(name='chungnam',reg_code='13')\n",
    "crawler.rg_crawling(name='jeonbuk',reg_code='14')\n",
    "crawler.rg_crawling(name='jeonnam',reg_code='15')\n",
    "crawler.rg_crawling(name='gyeongbuk',reg_code='16')\n",
    "crawler.rg_crawling(name='gyeongnam',reg_code='17')\n",
    "crawler.rg_crawling(name='jeju',reg_code='18')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "def check(region, region_detail):\n",
    "    region = eval(region)\n",
    "    region = region.drop_duplicates()\n",
    "    region_detail = eval(region_detail)\n",
    "    try:\n",
    "        print(region.shape[0],region_detail['2'].nunique(),\n",
    "region[(region['suplyTyNm']!='매입임대')]['rnAdres'].nunique())\n",
    "    except:\n",
    "        print(region.shape[0],region_detail[2].nunique(),\n",
    "region[(region['suplyTyNm']!='매입임대')]['rnAdres'].nunique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "for name in region:\n",
    "    print(name, end=' ')\n",
    "    check(name, name+'_detail') # 특정경우 홈페이지에서 크롤링이 되지 않았지만, 큰 문제는 아니라고 판단"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "seoul 840 591 597\n",
      "busan 775 76 76\n",
      "daegu 296 81 81\n",
      "incheon 193 66 67\n",
      "gwangju 736 72 72\n",
      "daejeon 302 46 46\n",
      "ulsan 35 24 24\n",
      "sejong 23 19 19\n",
      "gangwon 316 90 91\n",
      "chungbuk 343 88 88\n",
      "chungnam 643 95 95\n",
      "jeonbuk 301 93 93\n",
      "jeonnam 119 78 78\n",
      "gyeongbuk 184 100 100\n",
      "gyeongnam 623 100 100\n",
      "jeju 49 32 32\n",
      "gyeonggi 1450 483 483\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "for name in region:\n",
    "    globals()[name] = pd.read_csv(name+'.csv')\n",
    "    globals()[name+'_detail'] = pd.read_csv(name+'_detail.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "region = ['seoul', 'busan', 'daegu', 'incheon', 'gwangju','daejeon', 'ulsan','sejong',\n",
    "'gangwon','chungbuk','chungnam','jeonbuk','jeonnam','gyeongbuk','gyeongnam','jeju', 'gyeonggi']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "seoul.to_csv('seoul.csv',index=False,encoding='utf-8-sig') #840건, 597건\n",
    "seoul_detail.to_csv('seoul_detail.csv',index=False,encoding='utf-8-sig') #591건\n",
    "busan.to_csv('busan.csv',index=False,encoding='utf-8-sig') #775건, 76건\n",
    "busan_detail.to_csv('busan_detail.csv',index=False,encoding='utf-8-sig') #76건\n",
    "daegu.to_csv('daegu.csv',index=False,encoding='utf-8-sig') #296건, 81건\n",
    "daegu_detail.to_csv('daegu_detail.csv',index=False,encoding='utf-8-sig') #81건\n",
    "incheon.to_csv('incheon.csv',index=False,encoding='utf-8-sig') #193건, 67건\n",
    "incheon_detail.to_csv('incheon_detail.csv',index=False,encoding='utf-8-sig') # 66건 \n",
    "gwangju.to_csv('gwangju.csv',index=False,encoding='utf-8-sig') #736건, 72건\n",
    "gwangju_detail.to_csv('gwangju_detail.csv',index=False,encoding='utf-8-sig') #72건 \n",
    "daejeon.to_csv('daejeon.csv',index=False,encoding='utf-8-sig') #302건, 46건\n",
    "daejeon_detail.to_csv('daejeon_detail.csv',index=False,encoding='utf-8-sig') # 46건\n",
    "ulsan.to_csv('ulsan.csv',index=False,encoding='utf-8-sig') #35건 24건\n",
    "ulsan_detail.to_csv('ulsan_detail.csv',index=False,encoding='utf-8-sig') # 24건\n",
    "sejong.to_csv('sejong.csv',index=False,encoding='utf-8-sig') #23건 19건\n",
    "sejong_detail.to_csv('sejong_detail.csv',index=False,encoding='utf-8-sig') # 19건\n",
    "gangwon.to_csv('gangwon.csv',index=False,encoding='utf-8-sig') #316건 91건\n",
    "gangwon_detail.to_csv('gangwon_detail.csv',index=False,encoding='utf-8-sig') # 90건\n",
    "chungbuk.to_csv('chungbuk.csv',index=False,encoding='utf-8-sig') #343건 88건\n",
    "chungbuk_detail.to_csv('chungbuk_detail.csv',index=False,encoding='utf-8-sig') # 88건 \n",
    "chungnam.to_csv('chungnam.csv',index=False,encoding='utf-8-sig') #643건 95건\n",
    "chungnam_detail.to_csv('chungnam_detail.csv',index=False,encoding='utf-8-sig') #95건\n",
    "jeonbuk.to_csv('jeonbuk.csv',index=False,encoding='utf-8-sig') #301건 93건\n",
    "jeonbuk_detail.to_csv('jeonbuk_detail.csv',index=False,encoding='utf-8-sig') #93건\n",
    "jeonnam.to_csv('jeonnam.csv',index=False,encoding='utf-8-sig') #119건 78건\n",
    "jeonnam_detail.to_csv('jeonnam_detail.csv',index=False,encoding='utf-8-sig') #78건 \n",
    "gyeongbuk.to_csv('gyeongbuk.csv',index=False,encoding='utf-8-sig') #184건 100건\n",
    "gyeongbuk_detail.to_csv('gyeongbuk_detail.csv',index=False,encoding='utf-8-sig') # 100건\n",
    "gyeongnam.to_csv('gyeongnam.csv',index=False,encoding='utf-8-sig') #623건 100건\n",
    "gyeongnam_detail.to_csv('gyeongnam_detail.csv',index=False,encoding='utf-8-sig')# 100건 \n",
    "jeju.to_csv('jeju.csv',index=False,encoding='utf-8-sig') #49건 32건\n",
    "jeju_detail.to_csv('jeju_detail.csv',index=False,encoding='utf-8-sig') #32건"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "myhome = pd.concat([seoul,busan,daegu,incheon,gwangju,daejeon,ulsan,sejong,gangwon,\n",
    "chungbuk,chungnam,jeonbuk,jeonnam,gyeongbuk,gyeongnam,jeju,gyeonggi]).iloc[:,1:].drop_duplicates()\n",
    "\n",
    "myhome_detail = pd.concat([seoul_detail, busan_detail, daegu_detail, incheon_detail,\n",
    "gwangju_detail, daejeon_detail, ulsan_detail, sejong_detail, gangwon_detail, chungbuk_detail,\n",
    "chungnam_detail, jeonbuk_detail, jeonnam_detail, gyeongbuk_detail,\n",
    "gyeongnam_detail, jeju_detail,gyeonggi_detail]).iloc[:,1:].drop_duplicates()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "myhome = myhome[myhome['suplyTyNm']!='매입임대']\n",
    "detail_col =['임대종류','rnAdres','준공일자','hshldCo','주택유형','건물형태',\n",
    "'난방방식','승강기설치여부','insttDc','공급면적(전용)','공급면적(공용)',\n",
    "'임대보증금','임대료','전환보증금']\n",
    "myhome_detail.columns = detail_col"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "def str_to_num(name):\n",
    "    myhome_detail[name] = myhome_detail[name].str.replace(',','').str.replace('원','').str.replace('㎡','')\n",
    "    try:\n",
    "        myhome_detail[name] = myhome_detail[name].astype(int)  \n",
    "    except:\n",
    "        myhome_detail[name] = myhome_detail[name].astype(float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "str_to_num('공급면적(전용)')\n",
    "str_to_num('공급면적(공용)')\n",
    "str_to_num('임대보증금')\n",
    "str_to_num('임대료')\n",
    "str_to_num('전환보증금')\n",
    "str_to_num('hshldCo')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "myhome = pd.merge(myhome, myhome_detail, on=['rnAdres','hshldCo','insttDc'])\n",
    "myhome.to_csv('myhome.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}